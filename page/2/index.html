<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/cat_favicon_32.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/cat_favicon_16.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="Hi, I am Dennis, being as a data engineer for several years. I am enthusiastic about programming (Python and Java), studying and making money. Regarding entertainments, I enjoy playing badminton and t">
<meta property="og:type" content="website">
<meta property="og:title" content="Welcome to Dennis Blog">
<meta property="og:url" content="http://mikolaje.github.io/page/2/index.html">
<meta property="og:site_name" content="Welcome to Dennis Blog">
<meta property="og:description" content="Hi, I am Dennis, being as a data engineer for several years. I am enthusiastic about programming (Python and Java), studying and making money. Regarding entertainments, I enjoy playing badminton and t">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Welcome to Dennis Blog">
<meta name="twitter:description" content="Hi, I am Dennis, being as a data engineer for several years. I am enthusiastic about programming (Python and Java), studying and making money. Regarding entertainments, I enjoy playing badminton and t">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://mikolaje.github.io/page/2/"/>





  <title>Welcome to Dennis Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Welcome to Dennis Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">欢迎各位领导前来指导工作</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mikolaje.github.io/2019/celery_lock_task.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dennis">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to Dennis Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/celery_lock_task.html" itemprop="url">Celery让某个task一个一个地执行</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-02T11:07:10+08:00">
                2019-03-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python-backend/" itemprop="url" rel="index">
                    <span itemprop="name">python backend</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/celery_lock_task.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/celery_lock_task.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>最近有个需求是这样子的，某个task要求一定要一个一个地执行，不能并发执行。<br>比较简单的办法是直接将 celery worker启动为 一个进程: “-c 1”。 但是，这种方法会导致其它的task也只能单进程了。</p>
<p>后来通过Google，查找了很多例子，最普遍的一个做法是参考官方文档的做法， 代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> celery <span class="keyword">import</span> task</div><div class="line"><span class="keyword">from</span> celery.five <span class="keyword">import</span> monotonic</div><div class="line"><span class="keyword">from</span> celery.utils.log <span class="keyword">import</span> get_task_logger</div><div class="line"><span class="keyword">from</span> contextlib <span class="keyword">import</span> contextmanager</div><div class="line"><span class="keyword">from</span> django.core.cache <span class="keyword">import</span> cache</div><div class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5</div><div class="line"><span class="keyword">from</span> djangofeeds.models <span class="keyword">import</span> Feed</div><div class="line"></div><div class="line">logger = get_task_logger(__name__)</div><div class="line"></div><div class="line">LOCK_EXPIRE = <span class="number">60</span> * <span class="number">10</span>  <span class="comment"># Lock expires in 10 minutes</span></div><div class="line"></div><div class="line"><span class="meta">@contextmanager</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">memcache_lock</span><span class="params">(lock_id, oid)</span>:</span></div><div class="line">    timeout_at = monotonic() + LOCK_EXPIRE - <span class="number">3</span></div><div class="line">    <span class="comment"># cache.add fails if the key already exists</span></div><div class="line">    status = cache.add(lock_id, oid, LOCK_EXPIRE)  </div><div class="line">    <span class="comment"># 如果存在lock_id的话会返回False，不存在的话会返回True。这个也可以换成用Redis实现，比如用 setnx</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        <span class="keyword">yield</span> status</div><div class="line">    <span class="keyword">finally</span>:</div><div class="line">        <span class="comment"># memcache delete is very slow, but we have to use it to take</span></div><div class="line">        <span class="comment"># advantage of using add() for atomic locking</span></div><div class="line">        <span class="keyword">if</span> monotonic() &lt; timeout_at <span class="keyword">and</span> status:</div><div class="line">            <span class="comment"># don't release the lock if we exceeded the timeout</span></div><div class="line">            <span class="comment"># to lessen the chance of releasing an expired lock</span></div><div class="line">            <span class="comment"># owned by someone else</span></div><div class="line">            <span class="comment"># also don't release the lock if we didn't acquire it</span></div><div class="line">            cache.delete(lock_id)</div><div class="line"></div><div class="line"><span class="meta">@task(bind=True)</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">import_feed</span><span class="params">(self, feed_url)</span>:</span></div><div class="line">    <span class="comment"># The cache key consists of the task name and the MD5 digest</span></div><div class="line">    <span class="comment"># of the feed URL.</span></div><div class="line">    feed_url_hexdigest = md5(feed_url).hexdigest()</div><div class="line">    lock_id = <span class="string">'&#123;0&#125;-lock-&#123;1&#125;'</span>.format(self.name, feed_url_hexdigest)</div><div class="line">    logger.debug(<span class="string">'Importing feed: %s'</span>, feed_url)</div><div class="line">    <span class="keyword">with</span> memcache_lock(lock_id, self.app.oid) <span class="keyword">as</span> acquired:</div><div class="line">        <span class="keyword">if</span> acquired:</div><div class="line">            <span class="keyword">return</span> Feed.objects.import_feed(feed_url).url</div><div class="line">    logger.debug(</div><div class="line">        <span class="string">'Feed %s is already being imported by another worker'</span>, feed_url)</div></pre></td></tr></table></figure>
<p>但是，上面的逻辑只是在有task正执行的时候忽略了新增task。比如说有个import_feed task 正在运行，还没有运行完，<br>再调用apply_async的时候就会不做任何操作。</p>
<p>所以得在上面代码的基础上改一改。</p>
<h3 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h3><p>这里我用了一个上厕所的例子。假设有一个公共厕所。如果有人在用着这个厕所的时候其他人就不能使用了，得在旁边排队等候。<br>一次只能进去一个人。废话少说直接上代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="meta">@app.task(bind=True, base=ShitTask, max_retries=10)</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">shit_task</span><span class="params">(self, toilet_id)</span>:</span></div><div class="line">    lock_id = <span class="string">'&#123;0&#125;-lock'</span>.format(toilet_id)</div><div class="line">    shit_queue = <span class="string">'&#123;0&#125;-queue'</span>.format(self.name)</div><div class="line">    <span class="comment"># 这里我选用了Redis来处理队列</span></div><div class="line">    <span class="keyword">with</span> memcache_lock(lock_id, self.app.oid) <span class="keyword">as</span> acquired:</div><div class="line">        <span class="keyword">if</span> acquired:</div><div class="line">            <span class="comment"># 当进入到厕所的时候，先把门锁上（其他人就进不来了，然后再拉</span></div><div class="line">            print(<span class="string">'Oh yes, Lock the door and it is my time to shit. '</span>)</div><div class="line">            time.sleep(<span class="number">5</span>)</div><div class="line">            <span class="keyword">return</span> <span class="string">'I finished shit'</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="comment"># 有人在用厕所，得在外面等着 </span></div><div class="line">            print(<span class="string">'Oops, somebody engaged the toilet, I have to queue up'</span>)</div><div class="line">            rdb.lpush(shit_queue, json.dumps(list(self.request.args)))</div><div class="line">            <span class="comment"># 将其他人放到Redis里排队等候</span></div><div class="line">            <span class="keyword">raise</span> Ignore()</div></pre></td></tr></table></figure>
<p>上面代码是主要的task处理所及。另外，要先重写一下Task类的 after_return 方法，使得当没能执行的task（在门口排队的人）<br>在正在执行task（正在用厕所的人）成功执行完后，接着执行下一个task（下个人接着用厕所）。</p>
<p>完整代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding=u8</span></div><div class="line"><span class="keyword">from</span> celery <span class="keyword">import</span> Celery, Task</div><div class="line"><span class="keyword">from</span> celery.exceptions <span class="keyword">import</span> Ignore</div><div class="line"><span class="keyword">from</span> celery <span class="keyword">import</span> task</div><div class="line"><span class="keyword">import</span> redis</div><div class="line"><span class="keyword">import</span> pickle</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">from</span> celery.five <span class="keyword">import</span> monotonic</div><div class="line"><span class="keyword">from</span> celery.utils.log <span class="keyword">import</span> get_task_logger</div><div class="line"><span class="keyword">from</span> contextlib <span class="keyword">import</span> contextmanager</div><div class="line"><span class="keyword">import</span> time</div><div class="line"></div><div class="line">app = Celery(<span class="string">'tasks'</span>, broker=<span class="string">'redis://localhost:6379/10'</span>)</div><div class="line"></div><div class="line">logger = get_task_logger(__name__)</div><div class="line"></div><div class="line">LOCK_EXPIRE = <span class="number">60</span> * <span class="number">10</span>  <span class="comment"># Lock expires in 10 minutes</span></div><div class="line"></div><div class="line">rdb = redis.Redis(db=<span class="number">11</span>)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ShitTask</span><span class="params">(Task)</span>:</span></div><div class="line">    abstract = <span class="keyword">True</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">after_return</span><span class="params">(self, status, retval, task_id, args, kwargs, einfo)</span>:</span></div><div class="line">        print(status)</div><div class="line">        <span class="keyword">if</span> retval:</div><div class="line">            <span class="comment"># 这个retval的内容就是task return过来的内容</span></div><div class="line">            print(<span class="string">'somebody finished shit, calling the next one to shit'</span>)</div><div class="line">            shit_queue = <span class="string">'&#123;0&#125;-queue'</span>.format(self.name)</div><div class="line">            task_args = rdb.rpop(shit_queue)</div><div class="line"></div><div class="line">            <span class="keyword">if</span> task_args:</div><div class="line">                task_args = json.loads(task_args)</div><div class="line">                self.delay(*task_args)</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">pass</span></div><div class="line"></div><div class="line"><span class="meta">@contextmanager</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">memcache_lock</span><span class="params">(lock_id, oid)</span>:</span></div><div class="line">    timeout_at = monotonic() + LOCK_EXPIRE - <span class="number">3</span></div><div class="line">    <span class="comment"># status = cache.add(lock_id, oid, LOCK_EXPIRE)  # 如果lock_id 存在则返回False，如果不存在则返回True</span></div><div class="line">    status = rdb.setnx(lock_id, oid)</div><div class="line">    rdb.expire(lock_id, LOCK_EXPIRE)</div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        <span class="keyword">yield</span> status</div><div class="line">    <span class="keyword">finally</span>:</div><div class="line">        <span class="keyword">if</span> monotonic() &lt; timeout_at <span class="keyword">and</span> status:</div><div class="line">            <span class="comment"># 设置一个时间限制，一个人不能占用厕所太久，而且只有占用厕所的那人才能开锁把厕所门打开</span></div><div class="line">            print(<span class="string">'release the lock and open the door of the toilet %s'</span> % lock_id)</div><div class="line">            rdb.delete(lock_id)</div><div class="line"></div><div class="line"></div><div class="line"><span class="meta">@app.task(bind=True, base=ShitTask, max_retries=10)</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">shit_task</span><span class="params">(self)</span>:</span></div><div class="line">    print(<span class="string">'task name %s'</span> % self.name)</div><div class="line">    </div><div class="line">    lock_id = <span class="string">'&#123;0&#125;-lock'</span>.format(self.name)</div><div class="line">    shit_queue = <span class="string">'&#123;0&#125;-queue'</span>.format(self.name)</div><div class="line">    print(lock_id)</div><div class="line">    <span class="keyword">with</span> memcache_lock(lock_id, self.app.oid) <span class="keyword">as</span> acquired:</div><div class="line">        print(<span class="string">'acquired'</span>, acquired)</div><div class="line">        <span class="keyword">if</span> acquired:</div><div class="line">            print(<span class="string">'Oh yes, Lock the door and it is my time to shit. '</span>)</div><div class="line">            time.sleep(<span class="number">5</span>)</div><div class="line">            <span class="keyword">return</span> <span class="string">'I finished shit'</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            print(<span class="string">'Oops, somebody engaged the toilet, I have to queue up'</span>)</div><div class="line">            <span class="comment">#pending_task = pickle.dumps(self)</span></div><div class="line">            <span class="comment">#rdb.lpush(shit_queue, pending_task)</span></div><div class="line">            <span class="comment"># 不能用pickle 的去序列化task。在after_return load的时候会出现很诡异的现象。load出的task是第一个acquired的task</span></div><div class="line">            <span class="comment"># 改为用json来做序列化</span></div><div class="line">            rdb.lpush(shit_queue, json.dumps(list(self.request.args)))</div><div class="line">            <span class="keyword">raise</span> Ignore()</div></pre></td></tr></table></figure>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>可以新建一个test_celery项目来检验一下。新建一个目录名叫 test_celery<br>然后新建一个tasks.py文件，内容就是上面代码。<br>用下面命令来启动Celery worker，这里用了8个进程来处理。设置多点可以增加task的并行执行任务数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">celery -A tasks worker -l info -c 8</div></pre></td></tr></table></figure></p>
<p>然后，可以启动ipython 进行调用task。<br><img src="/images/2019/celery_lock_task/1d60a617.png" alt=""><br>快速地敲几个task.delay</p>
<p>在celery日志中我们可以看到两个shit_tasks 是一个接一个来运行的。而不是并行执行。<br><img src="/images/2019/celery_lock_task/50ef5fbc.png" alt=""></p>
<p>代码放在了：<br><a href="https://github.com/mikolaje/celery_toys/tree/master/test_lock" target="_blank" rel="external">https://github.com/mikolaje/celery_toys/tree/master/test_lock</a></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="http://docs.celeryproject.org/en/latest/tutorials/task-cookbook.html#ensuring-a-task-is-only-executed-one-at-a-time" target="_blank" rel="external">http://docs.celeryproject.org/en/latest/tutorials/task-cookbook.html#ensuring-a-task-is-only-executed-one-at-a-time</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mikolaje.github.io/2019/nz_travel.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dennis">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to Dennis Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/nz_travel.html" itemprop="url">新西兰十二日自由行攻略</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-20T11:00:10+08:00">
                2019-02-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/life/" itemprop="url" rel="index">
                    <span itemprop="name">life</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/nz_travel.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/nz_travel.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>新西兰:flag-nz:十二日自由行攻略<br>更多详情可上新西兰旅游局官方网站查询<a href="https://www.newzealand.com/cn/" target="_blank" rel="external">https://www.newzealand.com/cn/</a></p>
<p>:memo:签证：提前三个月办理即可，一般都能拿到有效期五年的签证。现在新西兰是电子签证，无需贴签，本人是找淘宝旅行社办理，如果个人不嫌麻烦完全可以自己登陆相关网站申请签证，蜂窝网有很全面的介绍，我是懒得自己弄。新西兰签证比欧美签证简单，银行卡半年流水只需三万，无需按指纹面试等，两周内可以出签。签证出来后留电子版或者打印出来，到新西兰过关时直接刷护照即可过关，都没人检查电子签，因为系统已有纪录。</p>
<p>另外如果是要转机的话，需要提前确认是否需要过境签。比如，在澳大利亚转机就要申请过境签。澳大利亚的过境签申请挺简单的，在官网注册个账号然后填个表就好了，免费的。</p>
<p><a href="https://immi.homeaffairs.gov.au/visas/getting-a-visa/visa-listing/transit-771" target="_blank" rel="external">https://immi.homeaffairs.gov.au/visas/getting-a-visa/visa-listing/transit-771</a></p>
<p>:airplane:飞机：建议提前买，签证没出来之前也可以买了（因为签证很容易过），越早买越便宜！直飞大概要11.5个小时，飞奥克兰的班次多且便宜。</p>
<p>我们来回买的都是在澳大利亚悉尼转机的。去的是维珍航空，回的是澳大利亚航空。维珍的机票比较便宜，便宜的缺点就是他们的refreshment好难吃，有一餐我根本就没吃饱，另外要了一小碗泡面。相比之下，澳大利亚航空的伙食就好太多了，吃得都好。</p>
<p>:dollar:现金：提前去银行换好新西兰币，汇率大概是1:4.6。准备好visa或者master卡，新西兰旅游景点很多可以刷微信、支付宝、银联。</p>
<p>:phone:电话卡：建议提前在淘宝买电话卡，比较便宜。朋友建议买Vodafone的卡，价格比较高，也可以买2degree的卡，华为背景价格便宜。我买了Vodafone和2degree的卡，感觉没啥区别，到了偏远地区都是没有信号。如果要自驾游的朋友最好提早在谷歌下载离线地图，免得走错路线。</p>
<p>:moneybag:保险：建议出发前买个基础保险，新西兰看病非常贵，发生拉肚子阑尾炎等情况必须看病，买了保险可以减轻负担。我们买的是安联保险，性价比很高。</p>
<p>:house:住宿：为了深入了解当地文化以及省钱，我们全程在Airbnb上订民宿，大家一定要订超赞房东，看住客的评论，以免入坑。</p>
<p>:bus:交通：新西兰交通费很贵，出租车尤其贵，Uber稍微比的士便宜点。公交车也比国内贵很多，如果是在皇后镇没办卡的情况下，每个人是五刀。办卡的话大概是2刀一次这样。自驾行虽然方便但是难度大，新西兰驾驶方向和国内相反，靠左行驶，山路多，当地人开车速度快。如果对国外驾驶规则不是很熟的话，不建议自驾。</p>
<p>具体行程:car:<br>前四天：奥克兰:boat:<br>奥克兰是新西兰最大的城市，一半是海水，一半是都市，是著名的风帆之都。这是我们在新西兰最喜欢的城市，大部分华人都住在奥克兰。我们参观了</p>
<p>【奥克兰战争纪念博物馆】</p>
<p><img src="/images/2019/nz_travel/DSC00223.JPG" alt="Sample Image Added via Markdown"></p>
<p>【伊甸山】</p>
<p>【天空塔】</p>
<p><img src="/images/2019/nz_travel/DSC00091.JPG" alt="Sample Image Added via Markdown"></p>
<p>【皇后大街】【海边码头】<br>强烈推荐新西兰唯一官方旅行社isite，在天空塔楼下就有一家，我们报了三次一日游，大巴包接送。最后一天，我们报了一日游前往【玛塔玛塔霍比特村】<br><img src="/images/2019/nz_travel/DSC00356.JPG" alt="Sample Image Added via Markdown"></p>
<p>，中土世界的童话小镇，满眼都是绿油油的草地。在奥克兰的交通方式就是uber和走路。<br>:fork_and_knife:推荐餐厅：Depot（天空塔下）、Giapo冰淇淋</p>
<p>中间四天：皇后镇:crown:<br>皇后镇是非常出名的旅游城市啦，超级多游客，中国游客尤其多。皇后镇衣食住行都很贵。皇后镇风光旖旎，生态环境也很好，新西兰的自来水可以直接喝。我们参观了</p>
<p>【格林诺奇】</p>
<p>【箭镇】</p>
<p>【瓦卡蒂普湖】</p>
<p><img src="/images/2019/nz_travel/IMG_3222.JPG" alt="Sample Image Added via Markdown"></p>
<p>【坐蒸汽船看牧场喂动物】</p>
<p><img src="/images/2019/nz_travel/IMG_3200.JPG" alt="Sample Image Added via Markdown"></p>
<p>皇后镇可以买优惠公交卡，10纽币可以坐5次，非常划算！最后一天，我们报了I-site的一日游，从皇后镇坐大巴到基督城，沿途经过库克山/蒂卡波湖/好牧羊人教堂。<br>:fork_and_knife:推荐餐厅：Fergburger汉堡</p>
<p><img src="/images/2019/nz_travel/IMG_3081.JPG" alt="Sample Image Added via Markdown"></p>
<p>最后两天：基督城:latin_cross:<br>基督城于2011年发生大地震，现在城市还没恢复过来，比较萧条，没什么人气。可以购买有轨复古电车:railway_car:一日游，随上随下，</p>
<p><img src="/images/2019/nz_travel/DSC00670.JPG" alt="Sample Image Added via Markdown"></p>
<p>在站点下车可参观【基督城博物馆】</p>
<p>【超级漂亮的海格利公园】</p>
<p><img src="/images/2019/nz_travel/DSC00650.JPG" alt="Sample Image Added via Markdown"></p>
<p>【基督城大教堂】</p>
<p><img src="/images/2019/nz_travel/IMG_3253.jpg" alt="Sample Image Added via Markdown"></p>
<p>【图书馆】</p>
<p>【纸板大教堂】</p>
<p>【皇后广场】基</p>
<p>督城内很多涂鸦，比较文艺。</p>
<p><img src="/images/2019/nz_travel/IMG_3266.JPG" alt="Sample Image Added via Markdown"></p>
<p>留一两天就够了。<br>newzealand.com<br>新西兰旅游局欢迎您 | 最全面最官方的新西兰旅游攻略<br>欢迎您来新西兰旅游。敬请浏览新西兰旅游局官方网站，了解新西兰旅游攻略、经典观光线路推荐、特色景点介绍、当地美酒佳肴、酒店住宿推荐、航班与机场信息等内容。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mikolaje.github.io/2019/ngrok_deployment.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dennis">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to Dennis Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/ngrok_deployment.html" itemprop="url">Ngrok服务器部署</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-02T12:07:10+08:00">
                2019-01-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/运维/" itemprop="url" rel="index">
                    <span itemprop="name">运维</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/ngrok_deployment.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/ngrok_deployment.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>自己使用Google Cloud，阿里云，AWS有好几年了，在云服务器上花了不少钱，有段时间做爬虫，需要较大的磁盘空间（几百G），每个月大概要5，600元。<br>一年下来就6，7钱了。想想，还是直接买一台主机或服务器在家里放着好了，也就几千块钱。于是我买了台主机在家里放着，配置远远比原来ECS的配置要高，<br>而且还更便宜。把数据全部迁移到了自己的主机，但很多时候自己都不在家，不可能把笨重的主机带出去外面。于是得想办法在其它地方通过网络连接到主机。<br>刚开选择用Teamviewer，可以远程连接到主机的桌面，我的主机的操作系统是Ubuntu的，感觉还行。但是，慢慢感觉效率不是很高，因为是用桌面远程，</p>
<p>所以网速要求，还是有点高，更大的问题是Teamviewer是收费的，而且价格不菲，这样成本算下来一年下来也要花费挺多钱。<br>于是，我想到了以前的花生壳 内网穿透映射，但那个也是收费的。终于找到了一个令我满意的解决方案—-Ngrok！</p>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>Ngrok到底好在哪里呢？ 首先，也是最重要的是它的成本底。<br>主机买服务的话也就10多块钱一个月，网上一搜就很多Ngrok的提供商；自己搭建的话，也就买一台虚拟机的价格，我买的是某云的ECS。大概也就几十来块钱。</p>
<p>其次，Ngrok可以把你家里的电脑当成服务器来使用，远程登陆SSH；或者作为数据库，暴露对应的端口提供服务；或者直接作为Web服务，直接提供http访问。<br>这使得不用买昂贵的云服务，省了不少钱。不够配置的话可以自己买内存，SSD增加机器配置。</p>
<h3 id="准备工作："><a href="#准备工作：" class="headerlink" title="准备工作："></a>准备工作：</h3><h4 id="需要购买的服务"><a href="#需要购买的服务" class="headerlink" title="需要购买的服务"></a>需要购买的服务</h4><ol>
<li>有一个外网的虚拟机，我用的是国内的阿里云的，操作系统是Ubuntu。</li>
<li>有个自己注册的域名。<br>需要添加2条域名解析：<br><img src="/images/2019/ngrok_deployment/647f55bb.png" alt=""></li>
</ol>
<h4 id="部署工作："><a href="#部署工作：" class="headerlink" title="部署工作："></a>部署工作：</h4><ol>
<li><p>apt-get install golang<br>因为ngrok是用Go 来写的，所以要安装一下Go环境</p>
</li>
<li><p>git clone <a href="https://github.com/inconshreveable/ngrok.git" target="_blank" rel="external">https://github.com/inconshreveable/ngrok.git</a><br>然后把ngrok的源码clone下来。</p>
</li>
</ol>
<h4 id="证书安装："><a href="#证书安装：" class="headerlink" title="证书安装："></a>证书安装：</h4><blockquote>
<p>使用ngrok.com官方服务时，我们使用的是官方的SSL证书。自己建立ngrok服务，需要我们生成自己的证书，并提供携带该证书的ngrok客户端。首先指定域名：</p>
</blockquote>
<p>进入ngrok目录后，运行下面的指令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> NGROK_DOMAIN=<span class="string">"ngrok.xfl.host"</span>  </div><div class="line">//这里换成你的自己注册的域名，比如你注册的域名为abc.com。这里可以填 ngrok.abc.com</div><div class="line"></div><div class="line">openssl genrsa -out rootCA.key 2048</div><div class="line">openssl req -x509 -new -nodes -key rootCA.key -subj <span class="string">"/CN=<span class="variable">$NGROK_DOMAIN</span>"</span> -days 5000 -out rootCA.pem</div><div class="line">openssl genrsa -out device.key 2048</div><div class="line">openssl req -new -key device.key -subj <span class="string">"/CN=<span class="variable">$NGROK_DOMAIN</span>"</span> -out device.csr</div><div class="line">openssl x509 -req -in device.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out device.crt -days 5000</div></pre></td></tr></table></figure></p>
<p>我们在编译可执行文件之前，需要把生成的证书分别替换到 assets/client/tls和assets/server/tls中，这两个目录分别存放着ngrok和ngrokd的默认证书。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cp rootCA.pem assets/client/tls/ngrokroot.crt</div><div class="line">cp device.crt assets/server/tls/snakeoil.crt</div><div class="line">cp device.key assets/server/tls/snakeoil.key</div></pre></td></tr></table></figure>
<h3 id="ngrok部署安装"><a href="#ngrok部署安装" class="headerlink" title="ngrok部署安装"></a>ngrok部署安装</h3><h4 id="编译ngrokd-和-ngrok"><a href="#编译ngrokd-和-ngrok" class="headerlink" title="编译ngrokd 和 ngrok"></a>编译ngrokd 和 ngrok</h4><p>首先需要知道，ngrokd 为服务端的执行文件，ngrok为客户端的执行文件。</p>
<p>有没有release的区别是，包含release的编译结果会把assets目录下的内容包括进去，从而可以独立执行。<br>如果你今后还要更换证书，建议编译不包含release的版本。。首先编译ngrok服务端（ngrokd），默认为Linux版本：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">make clean</div><div class="line">make release-server</div></pre></td></tr></table></figure></p>
<p>编译ngrokd后，我们来编译ngrok(客户端)<br>在编译客户端的时候需要指明对应的操作系统和构架：</p>
<p>Linux 平台 32 位系统：GOOS=linux GOARCH=386<br>Linux 平台 64 位系统：GOOS=linux GOARCH=amd64<br>Windows 平台 32 位系统：GOOS=windows GOARCH=386<br>Windows 平台 64 位系统：GOOS=windows GOARCH=amd64<br>MAC 平台 32 位系统：GOOS=darwin GOARCH=386<br>MAC 平台 64 位系统：GOOS=darwin GOARCH=amd64<br>ARM 平台：GOOS=linux GOARCH=arm</p>
<p>我的Ubuntu属于linux 64，所以我执行如下指令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">GOOS=linux GOARCH=amd64 make release-client</div></pre></td></tr></table></figure></p>
<h4 id="启动ngrokd"><a href="#启动ngrokd" class="headerlink" title="启动ngrokd"></a>启动ngrokd</h4><p>编译后生成两个文件分别为服务端（ngrokd）和客户端(ngrok)。切换到对应的文件夹，运行服务端：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">./ngrokd -domain=<span class="string">"<span class="variable">$NGROK_DOMAIN</span>"</span> -httpAddr=<span class="string">":801"</span> -httpsAddr=<span class="string">":802"</span></div><div class="line">//801 是访问的http端口，比如，在本例子中，访问http://ngrok.xfl.host:801 就可以看到映射出的网页</div></pre></td></tr></table></figure>
<p>参数-domain表示服务器域名，请改成你自己的域名；-httpAddr表示默认监听的HTTP端口，-httpsAddr表示默认监听的HTTPS端口，<br>因为我用不到所以都设置成空字符串”“来关闭监听，如果需要打开的话记得格式是:12345（冒号+端口号）这样的；-tunnelAddr表示服务器监听客户端连接的隧道端口号，格式和前面一样；<br>-log表示日志文件位置；还有个-log-level用来控制日志记录的事件级别，选项有DEBUG、INFO、WARNING、ERROR。</p>
<p>如果编译的是不带release的版本，还可以通过-tlsCrt和-tlsKey选项来指定证书文件的位置。</p>
<p>出现类似以下内容，则说明我们的服务器端ngrokd正常运行了:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[16:41:56 CST 2017/04/20] [INFO] (ngrok/log.(*PrefixLogger).Info:83) [registry] [tun] No affinity cache specified</div><div class="line">[16:41:56 CST 2017/04/20] [INFO] (ngrok/log.(*PrefixLogger).Info:83) [metrics] Reporting every 30 seconds</div><div class="line">[16:41:57 CST 2017/04/20] [INFO] (ngrok/log.Info:112) Listening for public http connections on [::]:80</div><div class="line">[16:41:57 CST 2017/04/20] [INFO] (ngrok/log.Info:112) Listening for public https connections on [::]:443</div><div class="line">[16:41:57 CST 2017/04/20] [INFO] (ngrok/log.Info:112) Listening for control and proxy connections on [::]:4443</div><div class="line">[16:41:57 CST 2017/04/20] [INFO] (ngrok/log.(*PrefixLogger).Info:83) [tun:627acc92] New connection from 42.53.196.242:9386</div><div class="line">[16:41:57 CST 2017/04/20] [DEBG] (ngrok/log.(*PrefixLogger).Debug:79) [tun:627acc92] Waiting to read message</div><div class="line">[16:41:57 CST 2017/04/20] [DEBG] (ngrok/log.(*PrefixLogger).Debug:79) [tun:627acc92] Reading message with length: 159</div></pre></td></tr></table></figure>
<h4 id="配置ngrok客户端"><a href="#配置ngrok客户端" class="headerlink" title="配置ngrok客户端"></a>配置ngrok客户端</h4><p>将之前编译好的客户端文件(ngrok 文件)拷贝到需要使用服务的设备（自己买的那台笨重的主机）上。</p>
<h4 id="启动ngrok客户端"><a href="#启动ngrok客户端" class="headerlink" title="启动ngrok客户端"></a>启动ngrok客户端</h4><p>在ngrok同路径下建立配置文件ngrok.yml<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="attr">server_addr:</span> <span class="string">"ngrok.xfl.host:4443"</span></div><div class="line"><span class="attr">trust_host_root_certs:</span> <span class="literal">false</span></div><div class="line"><span class="attr">tunnels:</span></div><div class="line"><span class="attr">  ssh:</span></div><div class="line"><span class="attr">    remote_port:</span> <span class="number">6666</span></div><div class="line"><span class="attr">    proto:</span></div><div class="line"><span class="attr">      tcp:</span> <span class="number">22</span></div></pre></td></tr></table></figure></p>
<p>server_addr端口默认4443，可通过ngrokd服务端启动修改端口。在tunnels里配置隧道信息，<br>注意http和https隧道可设置subdomain和auth，而tcp里只能设置remote_port。</p>
<p>使用如下命令启动ngrok客户端：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ngrok -log=stdout -config=./ngrok.yml start ssh</div></pre></td></tr></table></figure></p>
<p>正常启动，你将会看到如下日志：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">ngrok                                                                                                                                                                                     (Ctrl+C to quit)</div><div class="line">                                                                                                                                                                                                          </div><div class="line">Tunnel Status                 online                                                                                                                                                                      </div><div class="line">Version                       1.7/1.7                                                                                                                                                                     </div><div class="line">Forwarding                    http://demo.ngrok.xfl.host -&gt; 127.0.0.1:19999                                                                                                                               </div><div class="line">Forwarding                    https://demo.ngrok.xfl.host -&gt; 127.0.0.1:19999                                                                                                                              </div><div class="line">Web Interface                 127.0.0.1:4040                                                                                                                                                              </div><div class="line"># Conn                        0                                                                                                                                                                           </div><div class="line">Avg Conn Time                 0.00ms</div></pre></td></tr></table></figure></p>
<p>Notice:如果显示reconnecting说明连接有错，在运行时加入-log=stdout来进行debug。</p>
<ol>
<li>有可能是因为你的Ngrok服务器没有开 4443端口</li>
<li>有可能是域名没有解析成功</li>
</ol>
<h4 id="TL-DR"><a href="#TL-DR" class="headerlink" title="TL;DR"></a>TL;DR</h4><p>ngrok 的配置文件是完全可选的非常简单 YAML 格式文件，他可以允许你使用 ngrok 一些更高级的功能，例如：</p>
<p>同时运行多个隧道</p>
<ul>
<li>连接到自定义的 ngrok 服务器</li>
<li>调整 ngrok 一些很神秘的功能</li>
<li><p>ngrok 的配置文件默认从 ~/.ngrok 加载。你可以通过 -config 参数重写配置文件的地址</p>
</li>
<li><p>同时运行多个隧道<br>为了运行多个隧道，你需要在配置文件当中使用 tunnels 参数配置每个隧道。隧道的参数以字典的形式配置在配置文件当中。<br>举个例子，让我们来定义三个不同的隧道。第一个隧道是一个有认证的只转发 https 的隧道。第二个隧道转发我们自己机器的 22 端口以便让我可以通过隧道连接到自己的电脑。<br>最后，我们使用自己的域名创造了一个隧道，我们将要在黑客马拉松中展示这个。</p>
</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="attr">tunnels:</span></div><div class="line"><span class="attr">  client:</span></div><div class="line"><span class="attr">    auth:</span> <span class="string">"user:password"</span></div><div class="line"><span class="attr">    proto:</span></div><div class="line"><span class="attr">      https:</span> <span class="number">8080</span></div><div class="line"><span class="attr">  ssh:</span></div><div class="line"><span class="attr">    proto:</span></div><div class="line"><span class="attr">      tcp:</span> <span class="number">22</span></div><div class="line">  hacks.inconshreveable.com:</div><div class="line"><span class="attr">    proto:</span></div><div class="line"><span class="attr">      http:</span> <span class="number">9090</span></div></pre></td></tr></table></figure>
<p>通过 ngrok start 命令，我们可以同时运行三个隧道，后面要接上我们要启动的隧道名。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ngrok start client ssh hacks.inconshreveable.com</div></pre></td></tr></table></figure>
<ul>
<li>隧道设置<br>每一个隧道都可以设置以下五个参数：proto，subdomain，auth，hostname 以及 remote_port。<br>每一个隧道都必须定义 proto ，因为这定义了协议的类型以及转发的目标。当你在运行 http/https 隧道时， auth 参数是可选的，<br>同样， remote_port 也是可选的，他声明了某个端口将要作为远程服务器转发的端口，请注意这只适用于 TCP 隧道。<br>ngrok 使用每个隧道的名字做到子域名或者域名，但你可以重写他：</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="attr">tunnels:</span></div><div class="line"><span class="attr">  client:</span></div><div class="line"><span class="attr">    subdomain:</span> <span class="string">"example"</span></div><div class="line"><span class="attr">    auth:</span> <span class="string">"user:password"</span></div><div class="line"><span class="attr">    proto:</span></div><div class="line"><span class="attr">      https:</span> <span class="number">8080</span></div></pre></td></tr></table></figure>
<p>对于 TCP 隧道，你可以会通过 remote_port 参数来指定一个远程服务器的端口作为映射。如果没有声明，服务器将会给你随机分配一个端口。</p>
<h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><p>如果使用国内IP或者国内的域名的话，用http的话貌似因为要备案，所以访问不了。前两天我是可以正常访问的，但是过了两天后就突然访问不了了。<br>可以改为用TCP的方式比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">netdata:</div><div class="line">  remote_port: 801 </div><div class="line">  proto:</div><div class="line">    tcp: 19999</div></pre></td></tr></table></figure></p>
<p>访问 ngnrok.xfl.host:801 即可。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://morongs.github.io/2016/12/28/dajian-ngrok/" target="_blank" rel="external">https://morongs.github.io/2016/12/28/dajian-ngrok/</a><br><a href="https://luozm.github.io/ngrok" target="_blank" rel="external">https://luozm.github.io/ngrok</a><br><a href="https://imlonghao.com/28.html" target="_blank" rel="external">https://imlonghao.com/28.html</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mikolaje.github.io/2019/cdh_install.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dennis">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to Dennis Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/cdh_install.html" itemprop="url">CDH 在ubuntu上的部署和安装，以及一些坑</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-02T10:24:10+08:00">
                2019-01-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/cloudera/" itemprop="url" rel="index">
                    <span itemprop="name">cloudera</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/cdh_install.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/cdh_install.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近两天在自己电脑上搭建一个Cloudera Manager来玩玩。本来以为挺简单的，只是在Web UI上无脑下一步就好了，<br>但其实还是遇到挺多问题的。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="在服务器上的操作"><a href="#在服务器上的操作" class="headerlink" title="在服务器上的操作"></a>在服务器上的操作</h3><p>刚开始基本上，就是按照官网的步骤来走，首先做一些前置工作:</p>
<ol>
<li>配置下apt</li>
<li>安装JDK.</li>
<li>安装下NTP时间同步的程序；</li>
<li>安装好Mysql，MariaDB，Posgres。<br>其中的一个数据库，刚开始以为都要安装。。。然后又把MariaDB这些一个个卸载了；</li>
<li>在Mysql中创建一些CM所需的数据库和表。如下所是。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">CREATE DATABASE scm DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</div><div class="line">GRANT ALL ON scm.* TO &apos;scm&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;</div><div class="line"></div><div class="line">CREATE DATABASE amon DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</div><div class="line">GRANT ALL ON amon.* TO &apos;amon&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;</div><div class="line"></div><div class="line">CREATE DATABASE rman DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</div><div class="line">GRANT ALL ON rman.* TO &apos;rman&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;</div><div class="line"></div><div class="line">CREATE DATABASE hue DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</div><div class="line">GRANT ALL ON hue.* TO &apos;hue&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;</div><div class="line"></div><div class="line">CREATE DATABASE metastore DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</div><div class="line">GRANT ALL ON metastore.* TO &apos;hive&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;</div><div class="line"></div><div class="line">CREATE DATABASE sentry DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</div><div class="line">GRANT ALL ON sentry.* TO &apos;sentry&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;</div><div class="line"></div><div class="line">CREATE DATABASE nav DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</div><div class="line">GRANT ALL ON nav.* TO &apos;nav&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;</div><div class="line"></div><div class="line">CREATE DATABASE navms DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</div><div class="line">GRANT ALL ON navms.* TO &apos;navms&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;</div><div class="line"></div><div class="line">CREATE DATABASE oozie DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</div><div class="line">GRANT ALL ON oozie.* TO &apos;oozie&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;</div></pre></td></tr></table></figure>
<ol>
<li>通过scm_prepare_database.sh 脚本来进一步设置Manager Database<br>sudo /opt/cloudera/cm/schema/scm_prepare_database.sh [options] <databasetype> <databasename> <databaseuser> <password><br>只需要执行一次<code>sudo /opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm mypassword</code>就好了。</password></databaseuser></databasename></databasetype></li>
</ol>
<h3 id="在Web-UI上的安装"><a href="#在Web-UI上的安装" class="headerlink" title="在Web UI上的安装"></a>在Web UI上的安装</h3><ol>
<li>首先记得在每台机器上配置好/etc/hosts</li>
<li>在Web上的安装基本上就是点继续。有些地方要注意。<br>这一步会等待比较长的时间，会下载安装一些parcels。</li>
</ol>
<p><img src="/images/2019/cdh_install/323205c4.png" alt="Sample Image Added via Markdown"></p>
<ol>
<li>然后，基本上就是下一步了。到这一步，我是创建了一个叫cloudera的用户，要给与它sudo以及password-exempt<br><img src="/images/2019/cdh_install/cloudera_install.jpg" alt="Sample Image Added via Markdown"></li>
</ol>
<p>对了，因为我的是单机版的，所以HDFS那边会报错一个叫：副本不足的块 存在隐患。<br>这是因为只有一个节点，Block块无法，分配到其它的节点作为备份。默认是有2个备份Block分发到其它节点。</p>
<h3 id="启动CDH"><a href="#启动CDH" class="headerlink" title="启动CDH"></a>启动CDH</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo systemctl start cloudera-scm-server</div><div class="line"></div><div class="line"># 查看scm server日志，scm的全称是：The Service and Configuration Manager </div><div class="line">sudo tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log</div></pre></td></tr></table></figure>
<h3 id="停止CDH"><a href="#停止CDH" class="headerlink" title="停止CDH"></a>停止CDH</h3><p>有些时候我们要停机检修一下电脑，所以要停止Cluster。很简单，首先进入到CDH的Web UI的Cluster主界面, 左上角有个Action<br>，点一下弹出下拉条，然后选停止。等几分钟后集群的所有组件就会停止了。</p>
<p>然后进入到主节点的终端，输入<code>sudo systemctl stop cloudera-scm-server</code>，就全部停止了。</p>
<h2 id="CDH的一些配置"><a href="#CDH的一些配置" class="headerlink" title="CDH的一些配置"></a>CDH的一些配置</h2><h3 id="Yarn-RM-NM共用一个host"><a href="#Yarn-RM-NM共用一个host" class="headerlink" title="Yarn: RM,NM共用一个host"></a>Yarn: RM,NM共用一个host</h3><p>默认情况下Resource Manager会单独用一个节点。但是我的RM host内存和CPU都有剩余，跑app的时候把资源压在<br>device2上有点浪费了，我利用起device1的资源来。<br>首先进入到Yarn的版块，Action下拉框，点击Add Role Instance<br><img src="/images/2019/cdh_install/yarn_rm_nm1.png" alt="Sample Image Added via Markdown"><br><img src="/images/2019/cdh_install/yarn_rm_nm1.png" alt="Sample Image Added via Markdown"></p>
<h3 id="增加服务"><a href="#增加服务" class="headerlink" title="增加服务"></a>增加服务</h3><p>如果我们想新增加一些组件，比如Kafka或Spark，然后我们可以点击Cluster版块的Action下拉框，选中第一个 Add Service<br>进入新增Service的页面。</p>
<h2 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h2><h3 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h3><p>我增加一个节点的时候遇到如下报错<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Host with invalid Cloudera Manager GUID is detected</div><div class="line">...</div><div class="line">Error, CM server guid updated, expected c3b5fe15-5f29-434b-ae0a-4750b56c72ab, received dc1d28d4-4c78-4a07-919b-a9eaf7190d41</div></pre></td></tr></table></figure></p>
<p>解决方法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">验证如下配置文件，确定hostname是否正确</div><div class="line">$ nano /etc/cloudera-scm-agent/config.ini</div><div class="line">so that the hostname where the same as the command $ hostname returned.</div><div class="line">Then rm /var/lib/cloudera-scm-agent/cm_guid</div><div class="line">然后删除每个节点的cm_guid</div><div class="line">then I restarted the agent and the server of cloudera:</div><div class="line">然后重启</div><div class="line">$ service cloudera-scm-agent restart</div><div class="line">$ service cloudera-scm-server restart</div></pre></td></tr></table></figure></p>
<h3 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h3><p>在NameNode Format的时候遇到如下报错<br>Running in non-interactive mode, and data appears to exist in Storage Directory /dfs/nn. Not formatting.</p>
<p>解决方案：<br>删除/dfs/nn 以及 /dfs/dn里面的所有数据<br>因为之前我安装了一个单机集群，HDFS里面放了一些数据</p>
<h3 id="问题3"><a href="#问题3" class="headerlink" title="问题3"></a>问题3</h3><p>Cloudera 在Validate Hive Metastore schema的时候出现如下错误，发现metastore里面没有VERSION table<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">Fri Jul 19 14:06:33 CST 2019 WARN: Establishing SSL connection without server&apos;s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn&apos;t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to &apos;false&apos;. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.</div><div class="line">org.apache.hadoop.hive.metastore.HiveMetaException: Failed to get schema version, Cause:Table &apos;metastore.VERSION&apos; doesn&apos;t exist</div><div class="line">org.apache.hadoop.hive.metastore.HiveMetaException: Failed to get schema version, Cause:Table &apos;metastore.VERSION&apos; doesn&apos;t exist</div><div class="line">	at org.apache.hadoop.hive.metastore.CDHMetaStoreSchemaInfo.getMetaStoreSchemaVersion(CDHMetaStoreSchemaInfo.java:342)</div><div class="line">	at org.apache.hive.beeline.HiveSchemaTool.validateSchemaVersions(HiveSchemaTool.java:685)</div><div class="line">	at org.apache.hive.beeline.HiveSchemaTool.doValidate(HiveSchemaTool.java:578)</div><div class="line">	at org.apache.hive.beeline.HiveSchemaTool.main(HiveSchemaTool.java:1142)</div><div class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</div><div class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</div><div class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</div><div class="line">	at java.lang.reflect.Method.invoke(Method.java:498)</div><div class="line">	at org.apache.hadoop.util.RunJar.run(RunJar.java:313)</div><div class="line">	at org.apache.hadoop.util.RunJar.main(RunJar.java:227)</div><div class="line">*** schemaTool failed ***</div></pre></td></tr></table></figure></p>
<p>解决方案：<br><code>dennis@device1:/opt/cloudera/parcels/CDH/lib/hive/bin$ schematool -dbType mysql -initSchema -passWord password -userName hive</code></p>
<h3 id="问题4"><a href="#问题4" class="headerlink" title="问题4"></a>问题4</h3><p>在Hue上的hive上运行一些 insert 和count(*) 操作时候会一直卡住（stuck, hang），没有任何反应，也没报错。<br>看日志是说MR 还没有启动。在Cloudera的community上查到 要mapred-site.xml的参数 mapreduce.framework.name 设置为 local</p>
<p>于是我在CDH中的Yarn集群下修改了mapreduce.framework.name 为 local，然后重启集群后就成功了。 select count(*) 和 insert就不会卡住了。</p>
<h3 id="问题5"><a href="#问题5" class="headerlink" title="问题5"></a>问题5</h3><p>在hue上面可以正常地使用Hive。在device2下用hive cli没有问题。但在device1 下的bash执行hive command，里面输入show databases后报错：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">SemanticException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</div></pre></td></tr></table></figure></p>
<p> 解决方案：<br> 先用 hive -hiveconf hive.root.logger=DEBUG,console<br> 在调试，查看到更多有价值的报错信息。<br> 果然，查到如下信息：<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"> Caused by: java.io.IOException: Keystore was tampered with, or password was incorrect</div><div class="line">	at com.sun.crypto.provider.JceKeyStore.engineLoad(JceKeyStore.java:865) ~[sunjce_provider.jar:1.8.0_112]</div><div class="line">	at java.security.KeyStore.load(KeyStore.java:1445) ~[?:1.8.0_121]</div><div class="line">	at org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.locateKeystore(AbstractJavaKeyStoreProvider.java:322) ~[hadoop-common-3.0.0-cdh6.2.0.jar:?]</div><div class="line">	at org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.&lt;init&gt;(AbstractJavaKeyStoreProvider.java:86) ~[hadoop-common-3.0.0-cdh6.2.0.jar:?]</div><div class="line">	at org.apache.hadoop.security.alias.LocalJavaKeyStoreProvider.&lt;init&gt;(LocalJavaKeyStoreProvider.java:58) ~[hadoop-common-3.0.0-cdh6.2.0.jar:?]</div><div class="line"></div><div class="line">	at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:237) ~[hive-exec-2.1.1-cdh6.2.0.jar:2.1.1-cdh6.2.0]</div><div class="line">	... 23 more</div><div class="line">Caused by: java.security.UnrecoverableKeyException: Password verification failed</div></pre></td></tr></table></figure></p>
<p>按日志的报错信息来说是我的源数据库密码不对，于是我查看hive-site.xml配置文件，发现<br>/opt/cloudera/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373/lib/hive/conf/hive-site.xml<br>也就是/etc/hive/conf/hive-site.xml(我猜CDH会把上面目录的所有配置文件复制一遍到 /etc/hive/conf/下)<br>我之前把它改了，所以那配置有问题，我把它改为默认的配置重启后就恢复正常了！</p>
<h3 id="问题6"><a href="#问题6" class="headerlink" title="问题6"></a>问题6</h3><p>启动 cloudera-scm-server 时候报错如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Table &apos;metastore.CM_VERSION&apos; doesn&apos;t exist</div></pre></td></tr></table></figure></p>
<p> 解决方案：<br><code>sudo /opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm mypassword</code><br>重新执行下这条命令。之前我把所有的服务都执行了一遍（amon, rman, … metastore, … etc)，是我误解了scm_prepare_database.sh的作用。<br>按官网所说的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Cloudera Manager Server includes a script that can create and configure a database for itself. The script can:</div><div class="line">Create the Cloudera Manager Server database configuration file.</div><div class="line">(MariaDB, MySQL, and PostgreSQL) Create and configure a database for Cloudera Manager Server to use.</div><div class="line">(MariaDB, MySQL, and PostgreSQL) Create and configure a user account for Cloudera Manager Server.</div></pre></td></tr></table></figure></p>
<p>这个脚本只需要执行一次就好了，就是<code>sudo /opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm mypassword</code><br>然后重启cloudera-scm-server解决问题。此外，通过<code>/etc/cloudera-scm-server/db.properties</code> 也可以确定目前scm用的是哪个数据库。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://www.cloudera.com/documentation/enterprise/6/6.2/topics/introduction.html" target="_blank" rel="external">https://www.cloudera.com/documentation/enterprise/6/6.2/topics/introduction.html</a><br><a href="https://blog.csdn.net/qq_24409555/article/details/76139886" target="_blank" rel="external">https://blog.csdn.net/qq_24409555/article/details/76139886</a><br><a href="https://community.cloudera.com/t5/Batch-SQL-Apache-Hive/Hive-Errors-happend-when-execute-hive-service-metastore/m-p/93050#M3282" target="_blank" rel="external">https://community.cloudera.com/t5/Batch-SQL-Apache-Hive/Hive-Errors-happend-when-execute-hive-service-metastore/m-p/93050#M3282</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mikolaje.github.io/2018/huaqiangbei_black_market.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dennis">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to Dennis Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/huaqiangbei_black_market.html" itemprop="url">华强北被坑记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-22T19:07:10+08:00">
                2018-12-22
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/huaqiangbei_black_market.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/huaqiangbei_black_market.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="好奇心"><a href="#好奇心" class="headerlink" title="好奇心"></a>好奇心</h2><p>之前有段时间一直为了好奇，想拍摄一些比较隐蔽的探访视频然后放YouTube上赚点广告费。想了很久，终于跑到忍不住<br>跑到华强北去寻找买一个眼镜摄像仪。就是带着摄像头在眼镜上的偷拍神器。去到华强北摄像头市场里，问了好多商铺，<br>他们都不卖，当然是私底下地问，因为这东西肯定不是不能明着卖的。后来还是找了个路边站街拉客的大妈，一问就有了。<br>她让我跟着她走，走到一个稍微人少点地方，她打电话给卖这东西的贩子，然后就在那等那贩子过来。</p>
<p>10分钟后，一个矮矮的中年男子（四五十岁），拿着个黑色大袋子走过来，说带我去一个更少人的角落验货。终于看到了<br>传说中的眼镜拍摄神器。这玩意超出我的预期，并没有我想象中的那么好，因为它一看就有些不太对头，不像一个正常的眼镜，<br>左右两根支架特别粗，因为里面有电路板，还要放置MINI-SD卡。它的摄像头在眼镜的最中间位置，也就是连接两个镜片<br>的地方，不仔细看的话，不会发现，不过稍微仔细点看还是能看出来它是有个摄像头在上面的。</p>
<p>接着，那个贩子拍摄了一段视频，我感觉视频的质量，分别率不是很好，大概就是几百块钱手机的拍摄效果吧。虽然不太满意，<br>但感觉跟那贩子看了有点久，有点骑虎难下，最后还是买下来了，花了750，他开价是900块。终于止住我那段时间以来的好奇心和欲望。</p>
<p>这东西还不带SD卡，于是我还花了几十块钱买了个SD卡。那天总共花了850左右吧，现在想想感觉还是挺不值的，因为拿回来后<br>也就拍了一下，就再也没用过了，感觉就是一个玩具而已，没有什么实际的用途。</p>
<p><img src="/images/2018/huaqiangbei_black_market/36750b47.png" alt=""></p>
<p><img src="/images/2018/huaqiangbei_black_market/8984d475.png" alt=""></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>就当花钱买个教训吧，我记得，我不是我第一次在华强北被坑，以前还很想买一种录音手表，后来以色列人送了我一个，大概是一百多块钱吧，用了几次就扔了。<br>以后还是要注意下自己的消费欲望。买之前再三思考，这东西值不值。不过很多东西其实还是买来后才知道它值不值。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mikolaje.github.io/2018/ubuntu_shared_object.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dennis">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to Dennis Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/ubuntu_shared_object.html" itemprop="url">Ubuntu的.so文件问题</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-06T22:27:10+08:00">
                2018-11-06
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/ubuntu_shared_object.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/ubuntu_shared_object.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>昨天在anaconda的虚拟环境py3 下装uwsgi</p>
<p>但执行uwsgi命令的时候报错提示：<br>uwsgi: error while loading shared libraries: libpcre.so.1: cannot open…</p>
<p>找不到libpcre.so.1 这个动态链接库。</p>
<p>这个东西叫做 动态链接库。</p>
<ul>
<li>An .so file is a compiled library file. It stands for “Shared Object” and is analogous to a Windows DLL</li>
</ul>
<h3 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h3><p>首先我学习了几个linux命令：</p>
<ol>
<li>ldd命令用于打印程序或者库文件所依赖的共享库列表。<br>2.ldconfig命令的用途主要是在默认搜寻目录/lib和/usr/lib以及动态库配置文件/etc/ld.so.conf内所列的目录下，搜索出可共享的动态链接库（格式如lib<em>.so</em>）,进而创建出动态装入程序(ld.so)所需的连接和缓存文件。<br>3.locate 让使用者可以很快速的搜寻档案系统内是否有指定的档案。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">ldconfig /opt/anaconda3/lib/</div><div class="line">ldd /data/software/anaconda2/bin/uwsgi</div><div class="line">locate libcrypto.so.1.0.0</div><div class="line"></div><div class="line">libcrypto.so.1.0.0 =&gt; /data/software/anaconda2/lib/libcrypto.so.1.0.0的  (0x00007f90b5695000)</div><div class="line">表示libcrypto.so.1.0.0 用的是 /data/software/anaconda2/lib/libcrypto.so.1.0.0的 动态 链接库</div><div class="line">用locate libcrypto.so.1.0.0 查看系统一共有几个 libcrypto.so.1.0.0 动态链接库</div></pre></td></tr></table></figure>
<p>ldconfig的几点注意事项：</p>
<ol>
<li>往/lib和/usr/lib里面加东西，是不用修改/etc/ld.so.conf的，但是完了之后要调一下ldconfig，不然这个library会找不到。</li>
<li>想往上面两个目录以外加东西的时候，一定要修改/etc/ld.so.conf，然后再调用ldconfig，不然也会找不到。</li>
<li>比如安装了一个mysql到/usr/local/mysql，mysql有一大堆library在/usr/local/mysql/lib下面，这时就需要在/etc/ld.so.conf下面加一行/usr/local/mysql/lib，保存过后ldconfig一下，新的library才能在程序运行时被找到。</li>
<li>如果想在这两个目录以外放lib，但是又不想在/etc/ld.so.conf中加东西（或者是没有权限加东西）。那也可以，就是export一个全局变量LD_LIBRARY_PATH，然后运行程序的时候就会去这个目录中找library。一般来讲这只是一种临时的解决方案，在没有权限或临时需要的时候使用</li>
</ol>
<p>in my case:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">add the  line below in /etc/profile:</div><div class="line">export LD_LIBRARY_PATH=/data/software/anaconda2/lib</div><div class="line"></div><div class="line">ldconfig /lib/x86_64-linux-gnu/</div></pre></td></tr></table></figure></p>
<p>finished!</p>
<blockquote>
<p>另外 LD_LIBRARY_PATH的优先级是最高的。</p>
</blockquote>
<p>The order is documented in the manual of the dynamic linker, which is ld.so. It is:</p>
<ol>
<li>directories from LD_LIBRARY_PATH;</li>
<li>directories from /etc/ld.so.conf;</li>
<li>/lib;</li>
<li>/usr/lib.<br>(I’m simplifying a little, see the manual for the full details.)</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">The order makes sense when you consider that it&apos;s the only way to override a library in a default location with a custom library.</div><div class="line">LD_LIBRARY_PATH is a user setting, it has to come before the others. /etc/ld.so.conf is a local setting, it comes before the operating system default.</div><div class="line">So as a user, if I want to run a program with a different version of a library, I can run the program with LD_LIBRARY_PATH containing the location of that different library version.</div><div class="line">And as an administrator, I can put a different version of the library in /usr/local/lib and list /usr/local/lib in /etc/ld.so.conf.</div></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mikolaje.github.io/2018/hive_udf.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dennis">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to Dennis Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/hive_udf.html" itemprop="url">Hive UDF 快速教程</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-02T12:07:10+08:00">
                2018-08-02
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/hive_udf.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/hive_udf.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="Step1"><a href="#Step1" class="headerlink" title="Step1"></a>Step1</h3><p>首先，我们创建一个目录 udf_test/;<br>创建子目录org/dennis/udf<br>在子目录里创建一个MyUpper.java文件。里面内容为：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> org.dennis.udf;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDF;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">MyUpper</span> <span class="keyword">extends</span> <span class="title">UDF</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">public</span> Text <span class="title">evaluate</span><span class="params">(<span class="keyword">final</span> Text s)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (s == <span class="keyword">null</span>) &#123; <span class="keyword">return</span> <span class="keyword">null</span>; &#125;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Text(s.toString().toUpperCase());</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="Step2"><a href="#Step2" class="headerlink" title="Step2"></a>Step2</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">javac -cp  /opt/cloudera/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373/hive-exec-2.1.1-cdh6.2.0.jar): \</div><div class="line">/opt/cloudera/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373/jars/hadoop-common.jar \</div><div class="line">org/dennis/udf/MyUpper.java</div></pre></td></tr></table></figure>
<p>这里我们要把依赖的jar包写进来，这里我们依赖hive-exec*.jar 以及 hadoop-common.jar</p>
<p>javac -cp 的作用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">javac -cp 指明了.java文件里import的类的位置</div><div class="line"></div><div class="line">java -cp 指明了执行这个class文件所需要的所有类的包路径-即系统类加载器的路径（涉及到类加载机制）</div><div class="line"></div><div class="line">路径在linux中用：隔开  在windows中用；隔开</div></pre></td></tr></table></figure></p>
<h3 id="Step3"><a href="#Step3" class="headerlink" title="Step3"></a>Step3</h3><p>生成一个jar文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">jar -cf myudfs.jar  -C . .</div><div class="line">会在当前目录下生成myudfs.jar 文件</div></pre></td></tr></table></figure></p>
<h3 id="Step4"><a href="#Step4" class="headerlink" title="Step4"></a>Step4</h3><p>进入Hive命令行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">hive&gt; add jar myudfs.jar;</div><div class="line">Added [myudfs.jar] to class path</div><div class="line">Added resources: [myudfs.jar]</div><div class="line">hive&gt; create temporary function dennisUpper as &apos;org.dennis.udf.MyUpper&apos;;</div><div class="line">OK</div><div class="line">Time taken: 0.067 seconds</div><div class="line">hive&gt;</div></pre></td></tr></table></figure></p>
<p>搞定！</p>
<p>另外，也可以在Hue上点击 setting后，上传对应的jar文件，然后将对应的function name 和 class name也填一下就OK了。<br><img src="/images/2018/hive_udf/hue_udf_upload.jpg" alt="Sample Image Added via Markdown"></p>
<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><p>有时候我们add jar后，create function时候会出现如下报错：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Added resources: [myudfs.jar]</div><div class="line">hive&gt; create temporary function dennisUpper as &apos;org.dennis.udf.MyUpper&apos;;</div><div class="line">FAILED: Class org.dennis.udf.MyUpper not found</div><div class="line">FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.FunctionTask</div></pre></td></tr></table></figure></p>
<p>我们可以解压一下jar包检查下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">unzip myudf.jar -d check_jar</div><div class="line">解压到 check_jar目录</div></pre></td></tr></table></figure></p>
<p>如果有的话，check_dir下应该是有这么一个目录文件:<br><code>org/dennis/udf/MyUpper.class</code></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mikolaje.github.io/2018/hive_optimization.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dennis">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to Dennis Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/hive_optimization.html" itemprop="url">Hive 优化</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-02T12:07:10+08:00">
                2018-06-02
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/hive_optimization.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/hive_optimization.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>对于如果join中有小表的话，可以开启map</p>
<h3 id="Dynamic-Partition-Pruning-for-Hive-Map-Joins"><a href="#Dynamic-Partition-Pruning-for-Hive-Map-Joins" class="headerlink" title="Dynamic Partition Pruning for Hive Map Joins"></a>Dynamic Partition Pruning for Hive Map Joins</h3><p>You can enable dynamic partition pruning for map joins when you are running Hive on Spark (HoS), it is not available for Hive on MapReduce.<br>Dynamic partition pruning (DPP) is a database optimization that can significantly decrease the amount of data that a query scans, thereby executing your workloads faster.<br>DPP achieves this by dynamically determining and eliminating the number of partitions that a query must read from a partitioned table.</p>
<p>Map joins also optimize how Hive executes queries. They cause a small table to be scanned and loaded in memory as a hash table<br>so that a fast join can be performed entirely within a mapper without having to use another reduce step.<br>If you have queries that join small tables, map joins can make them execute much faster.<br>Map joins are enabled by default in CDH with the Enable MapJoin Optimization setting for HiveServer2 in Cloudera Manager.<br>Hive automatically uses map joins for join queries that involve a set of tables where:</p>
<ul>
<li>There is one large table and there is no limit on the size of that large table.</li>
<li>All other tables involved in the join must have an aggregate size under the value set for Hive Auto Convert Join Noconditional Size for HiveServer2, which is set to 20MB by default in Cloudera Manager.</li>
</ul>
<p>关于map-side join的配置:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">SET hive.auto.convert.join=true;</div><div class="line">SET hive.auto.convert.join.noconditionaltask.size=&lt;number_in_megabytes&gt;;</div></pre></td></tr></table></figure></p>
<h2 id="一次调优实战"><a href="#一次调优实战" class="headerlink" title="一次调优实战"></a>一次调优实战</h2><p>最近在ETL过程中发现有条SQL执行时间非常长，其实数据量很小的，但为什么这么长呢。我带着极度好奇，抱着死缠烂打的精神，怎么也要把<br>问题给解决掉。SQL是这样的:<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="number">1</span>) <span class="keyword">from</span> zhihu_answer </div><div class="line"><span class="keyword">where</span> ym <span class="keyword">in</span> (<span class="keyword">select</span> <span class="keyword">distinct</span>(ym) <span class="keyword">from</span> zhihu.zhihu_answer_increment);</div></pre></td></tr></table></figure></p>
<p>先说说这两个表数据量吧：<br>zhihu_answer数据量大概是一亿，zhihu_answer_increment 也就是几十万条。<br>首先，我用<code>explain extended</code>查看下执行计划:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div></pre></td><td class="code"><pre><div class="line">explain extended</div><div class="line">select count(1) from zhihu_answer </div><div class="line">where ym in (select distinct(ym) from zhihu.zhihu_answer_increment);</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">Explain	</div><div class="line">STAGE DEPENDENCIES:	</div><div class="line">  Stage-3 is a root stage	</div><div class="line">  Stage-5 depends on stages: Stage-3 , consists of Stage-6, Stage-1	</div><div class="line">  Stage-6 has a backup stage: Stage-1	</div><div class="line">  Stage-4 depends on stages: Stage-6	</div><div class="line">  Stage-2 depends on stages: Stage-1, Stage-4	</div><div class="line">  Stage-1	</div><div class="line">  Stage-0 depends on stages: Stage-2	</div><div class="line">	</div><div class="line">STAGE PLANS:	</div><div class="line">  Stage: Stage-3	</div><div class="line">    Map Reduce	</div><div class="line">      Map Operator Tree:	</div><div class="line">          TableScan	</div><div class="line">            alias: zhihu_answer_increment	</div><div class="line">            filterExpr: ym is not null (type: boolean)	</div><div class="line">            Statistics: Num rows: 347468 Data size: 73315748 Basic stats: COMPLETE Column stats: COMPLETE	</div><div class="line">            GatherStats: false	</div><div class="line">            Select Operator	</div><div class="line">              expressions: ym (type: string)	</div><div class="line">              outputColumnNames: ym	</div><div class="line">              Statistics: Num rows: 347468 Data size: 73315748 Basic stats: COMPLETE Column stats: COMPLETE	</div><div class="line">              Group By Operator	</div><div class="line">                keys: ym (type: string)	</div><div class="line">                mode: hash	</div><div class="line">                outputColumnNames: _col0	</div><div class="line">                Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE	</div><div class="line">                Reduce Output Operator	</div><div class="line">                  key expressions: _col0 (type: string)	</div><div class="line">                  null sort order: a	</div><div class="line">                  sort order: +	</div><div class="line">                  Map-reduce partition columns: _col0 (type: string)	</div><div class="line">                  Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE	</div><div class="line">                  tag: -1	</div><div class="line">                  auto parallelism: false	</div><div class="line">      Execution mode: vectorized	</div><div class="line">      Path -&gt; Alias:	</div><div class="line">        nullscan://null/zhihu.zhihu_answer_increment/part_ym=201902_ [sq_1:zhihu_answer_increment]	</div><div class="line">      Path -&gt; Partition:	</div><div class="line">        nullscan://null/zhihu.zhihu_answer_increment/part_ym=201902_ 	</div><div class="line">          Partition	</div><div class="line">            input format: org.apache.hadoop.hive.ql.io.OneNullRowInputFormat	</div><div class="line">            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	</div><div class="line">            partition values:	</div><div class="line">              ym 201902	</div><div class="line">            properties:	</div><div class="line">              COLUMN_STATS_ACCURATE &#123;&quot;BASIC_STATS&quot;:&quot;true&quot;&#125;	</div><div class="line">              bucket_count 256	</div><div class="line">              bucket_field_name answer_id	</div><div class="line">              columns admin_closed_comment,answer_content,answer_created,answer_id,answer_updated,author_headline,author_id,author_name,author_type,author_url_token,avatar_url,badge_num,can_comment,comment_count,gender,insert_time,is_advertiser,is_collapsed,is_copyable,is_org,question_created,question_id,question_title,question_type,reward_member_count,reward_total_money,voteup_count	</div><div class="line">              columns.comments 	</div><div class="line">              columns.types boolean:string:string:string:string:string:string:string:string:string:string:smallint:boolean:int:string:string:boolean:boolean:boolean:boolean:string:string:string:string:int:int:int	</div><div class="line">              file.inputformat org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat	</div><div class="line">              file.outputformat org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat	</div><div class="line">              location hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer_increment/ym=201902	</div><div class="line">              name zhihu.zhihu_answer_increment	</div><div class="line">              numFiles 256	</div><div class="line">              numRows 347468	</div><div class="line">              partition_columns ym	</div><div class="line">              partition_columns.types string	</div><div class="line">              rawDataSize 9381636	</div><div class="line">              serialization.ddl struct zhihu_answer_increment &#123; bool admin_closed_comment, string answer_content, string answer_created, string answer_id, string answer_updated, string author_headline, string author_id, string author_name, string author_type, string author_url_token, string avatar_url, i16 badge_num, bool can_comment, i32 comment_count, string gender, string insert_time, bool is_advertiser, bool is_collapsed, bool is_copyable, bool is_org, string question_created, string question_id, string question_title, string question_type, i32 reward_member_count, i32 reward_total_money, i32 voteup_count&#125;	</div><div class="line">              serialization.format 1	</div><div class="line">              serialization.lib org.apache.hadoop.hive.serde2.NullStructSerDe	</div><div class="line">              totalSize 433473813	</div><div class="line">              transient_lastDdlTime 1571983508	</div><div class="line">            serde: org.apache.hadoop.hive.serde2.NullStructSerDe	</div><div class="line">          	</div><div class="line">              input format: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat	</div><div class="line">              output format: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat	</div><div class="line">              properties:	</div><div class="line">                bucket_count 256	</div><div class="line">                bucket_field_name answer_id	</div><div class="line">                columns admin_closed_comment,answer_content,answer_created,answer_id,answer_updated,author_headline,author_id,author_name,author_type,author_url_token,avatar_url,badge_num,can_comment,comment_count,gender,insert_time,is_advertiser,is_collapsed,is_copyable,is_org,question_created,question_id,question_title,question_type,reward_member_count,reward_total_money,voteup_count	</div><div class="line">                columns.comments 	</div><div class="line">                columns.types boolean:string:string:string:string:string:string:string:string:string:string:smallint:boolean:int:string:string:boolean:boolean:boolean:boolean:string:string:string:string:int:int:int	</div><div class="line">                file.inputformat org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat	</div><div class="line">                file.outputformat org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat	</div><div class="line">                location hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer_increment	</div><div class="line">                name zhihu.zhihu_answer_increment	</div><div class="line">                partition_columns ym	</div><div class="line">                partition_columns.types string	</div><div class="line">                serialization.ddl struct zhihu_answer_increment &#123; bool admin_closed_comment, string answer_content, string answer_created, string answer_id, string answer_updated, string author_headline, string author_id, string author_name, string author_type, string author_url_token, string avatar_url, i16 badge_num, bool can_comment, i32 comment_count, string gender, string insert_time, bool is_advertiser, bool is_collapsed, bool is_copyable, bool is_org, string question_created, string question_id, string question_title, string question_type, i32 reward_member_count, i32 reward_total_money, i32 voteup_count&#125;	</div><div class="line">                serialization.format 1	</div><div class="line">                serialization.lib org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe	</div><div class="line">                transient_lastDdlTime 1571983018	</div><div class="line">              serde: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe	</div><div class="line">              name: zhihu.zhihu_answer_increment	</div><div class="line">            name: zhihu.zhihu_answer_increment	</div><div class="line">      Truncated Path -&gt; Alias:	</div><div class="line">        nullscan://null/zhihu.zhihu_answer_increment/part_ym=201902_ [sq_1:zhihu_answer_increment]	</div><div class="line">      Needs Tagging: false	</div><div class="line">      Reduce Operator Tree:	</div><div class="line">        Group By Operator	</div><div class="line">          keys: KEY._col0 (type: string)	</div><div class="line">          mode: mergepartial	</div><div class="line">          outputColumnNames: _col0	</div><div class="line">          Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE	</div><div class="line">          Group By Operator	</div><div class="line">            keys: _col0 (type: string)	</div><div class="line">            mode: hash	</div><div class="line">            outputColumnNames: _col0	</div><div class="line">            Statistics: Num rows: 1 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE	</div><div class="line">            File Output Operator	</div><div class="line">              compressed: false	</div><div class="line">              GlobalTableId: 0	</div><div class="line">              directory: hdfs://device1:8020/tmp/hive/hive/7f0887a3-8c5a-44b6-b5ef-f0c7530a6b15/hive_2019-10-25_14-46-02_198_8962679143430564511-1/-mr-10004	</div><div class="line">              NumFilesPerFileSink: 1	</div><div class="line">              table:	</div><div class="line">                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat	</div><div class="line">                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat	</div><div class="line">                  properties:	</div><div class="line">                    columns _col0	</div><div class="line">                    columns.types string	</div><div class="line">                    escape.delim \	</div><div class="line">                    serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe	</div><div class="line">                  serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe	</div><div class="line">              TotalFiles: 1	</div><div class="line">              GatherStats: false	</div><div class="line">              MultiFileSpray: false	</div><div class="line">	</div><div class="line">  Stage: Stage-5	</div><div class="line">    Conditional Operator	</div><div class="line">	</div><div class="line">  Stage: Stage-6	</div><div class="line">    Map Reduce Local Work	</div><div class="line">      Alias -&gt; Map Local Tables:	</div><div class="line">        $INTNAME 	</div><div class="line">          Fetch Operator	</div><div class="line">            limit: -1	</div><div class="line">      Alias -&gt; Map Local Operator Tree:	</div><div class="line">        $INTNAME 	</div><div class="line">          TableScan	</div><div class="line">            GatherStats: false	</div><div class="line">            HashTable Sink Operator	</div><div class="line">              keys:	</div><div class="line">                0 ym (type: string)	</div><div class="line">                1 _col0 (type: string)	</div><div class="line">              Position of Big Table: 0	</div><div class="line">	</div><div class="line">  Stage: Stage-4	</div><div class="line">    Map Reduce	</div><div class="line">      Map Operator Tree:	</div><div class="line">          TableScan	</div><div class="line">            alias: zhihu_answer	</div><div class="line">            filterExpr: ym is not null (type: boolean)	</div><div class="line">            Statistics: Num rows: 102075765 Data size: 21537986328 Basic stats: COMPLETE Column stats: COMPLETE	</div><div class="line">            GatherStats: false	</div><div class="line">            Map Join Operator	</div><div class="line">              condition map:	</div><div class="line">                   Left Semi Join 0 to 1	</div><div class="line">              keys:	</div><div class="line">                0 ym (type: string)	</div><div class="line">                1 _col0 (type: string)	</div><div class="line">              Position of Big Table: 0	</div><div class="line">              Statistics: Num rows: 4253156 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE	</div><div class="line">              Group By Operator	</div><div class="line">                aggregations: count(1)	</div><div class="line">                mode: hash	</div><div class="line">                outputColumnNames: _col0	</div><div class="line">                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE	</div><div class="line">                File Output Operator	</div><div class="line">                  compressed: false	</div><div class="line">                  GlobalTableId: 0	</div><div class="line">                  directory: hdfs://device1:8020/tmp/hive/hive/7f0887a3-8c5a-44b6-b5ef-f0c7530a6b15/hive_2019-10-25_14-46-02_198_8962679143430564511-1/-mr-10003	</div><div class="line">                  NumFilesPerFileSink: 1	</div><div class="line">                  table:	</div><div class="line">                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat	</div><div class="line">                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat	</div><div class="line">                      properties:	</div><div class="line">                        columns _col0	</div><div class="line">                        columns.types bigint	</div><div class="line">                        escape.delim \	</div><div class="line">                        serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe	</div><div class="line">                      serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe	</div><div class="line">                  TotalFiles: 1	</div><div class="line">                  GatherStats: false	</div><div class="line">                  MultiFileSpray: false	</div><div class="line">      Local Work:	</div><div class="line">        Map Reduce Local Work	</div><div class="line">      Path -&gt; Alias:	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201705 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201706 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201707 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201708 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201709 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201710 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201711 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201712 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201801 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201802 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201803 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201804 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201805 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201806 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201807 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201808 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201809 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201810 [zhihu_answer]	</div><div class="line">        hdfs://device1:8020/user/hive/warehouse/zhihu.db/zhihu_answer/ym=201811 [zhihu_answer]</div></pre></td></tr></table></figure></p>
<p>一脸懵逼，不会看呀。。<br>然后我测试了下单独执行：<code>select distinct(ym) from zhihu_answer_increment;</code>，也就不到2分钟就出结果了。为什么组合在一起就要这么长时间呢？？<br>这条SQL的执行结果就是<code>&quot;201902&quot;</code>。我把这个结果复制进去执行：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="number">1</span>) <span class="keyword">from</span> zhihu_answer <span class="keyword">where</span> ym <span class="keyword">in</span> (<span class="number">201902</span>);</div></pre></td></tr></table></figure></p>
<p>可能是因为我之前执行过的原因，这条语句的执行时间基本上是秒出呀。几秒内就出结果了。</p>
<p>我再一次执行了那句执行时间很长的SQL，看它的执行时候的log，我发现慢原因是在Stage-4 ！！！回到上面那个explain的信息，我发现Hive在做全表扫描呀！Why?<br>为什么要做全表扫描呢？ 因为Hive还是要join的 in （select ** ） 这种子查询中用的是semi join，所以要进行join，它就会进行全表扫描。我的解释不是很详细，<br>但隐隐约约我能理解为什么Hive在这要做全表扫描了，其实如果写死的话，比如where ym in （201902）它就不会做join，也就不用全表扫描了。所以解决方案还是要能<br>拿到 <code>201902</code>这个变量，这个value，再拼接到Hive SQL中。我查了下，Hive貌似目前还不支持以SQL查询结果作为新的SQL变量。所以，暂时还是以这种办法解决吧。</p>
<p>让我无比开心的是，改进后，SQL执行快了N倍，因为避免了全表扫描。从原来2个小时的执行，变为了几分钟！</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过Explain打印看看执行计划有哪些；<br>通过执行的log看看到底是哪个Stage耗时比较长；</p>
<h1 id="Referrence"><a href="#Referrence" class="headerlink" title="Referrence"></a>Referrence</h1><p><a href="https://docs.cloudera.com/documentation/enterprise/latest/topics/admin_hos_oview.html#concept_i22_l1h_1v" target="_blank" rel="external">https://docs.cloudera.com/documentation/enterprise/latest/topics/admin_hos_oview.html#concept_i22_l1h_1v</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mikolaje.github.io/2018/kafka_intro.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dennis">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to Dennis Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/kafka_intro.html" itemprop="url">Kafka Introduction</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-02T12:07:10+08:00">
                2018-03-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/kafka/" itemprop="url" rel="index">
                    <span itemprop="name">kafka</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/kafka_intro.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/kafka_intro.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>最近面试经常会被问到Kafka的问题。看了很多Kafka的介绍，发现还是美团技术团队总结的最清楚易懂。下面转了美团的关于Kafka的一篇文章</li>
</ul>
<h2 id="Kafka是什么"><a href="#Kafka是什么" class="headerlink" title="Kafka是什么"></a>Kafka是什么</h2><p>Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统(也可以当做MQ系统)，常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。</p>
<p>一个商业化消息队列的性能好坏，其文件存储机制设计是衡量一个消息队列服务技术水平和最关键指标之一。 下面将从Kafka文件存储机制和物理结构角度，分析Kafka是如何实现高效文件存储，及实际应用效果。</p>
<p>Kafka部分名词解释如下：</p>
<ul>
<li>Broker：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。</li>
<li>Topic：一类消息，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发。</li>
<li>Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。</li>
<li>Segment：partition物理上由多个segment组成，下面2.2和2.3有详细说明。</li>
<li>offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset,用于partition唯一标识一条消息.</li>
</ul>
<p>分析过程分为以下4个步骤：</p>
<ul>
<li>topic中partition存储分布</li>
<li>partiton中文件存储方式</li>
<li>partiton中segment文件存储结构</li>
<li>在partition中如何通过offset查找message</li>
</ul>
<p>通过上述4过程详细分析，我们就可以清楚认识到kafka文件存储机制的奥秘。</p>
<h2 id="2-1-topic中partition存储分布"><a href="#2-1-topic中partition存储分布" class="headerlink" title="2.1 topic中partition存储分布"></a>2.1 topic中partition存储分布</h2><p>假设实验环境中Kafka集群只有一个broker，xxx/message-folder为数据文件存储根目录，在Kafka broker中server.properties文件配置(参数log.dirs=xxx/message-folder)，例如创建2个topic名称分别为report_push、launch_info, partitions数量都为partitions=4 存储路径和目录规则为： xxx/message-folder<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">|--report_push-0</div><div class="line">|--report_push-1</div><div class="line">|--report_push-2</div><div class="line">|--report_push-3</div><div class="line">|--launch_info-0</div><div class="line">|--launch_info-1</div><div class="line">|--launch_info-2</div><div class="line">|--launch_info-3</div></pre></td></tr></table></figure></p>
<p>在Kafka文件存储中，同一个topic下有多个不同partition，每个partition为一个目录，partiton命名规则为topic名称+有序序号，第一个partiton序号从0开始，序号最大值为partitions数量减1。 如果是多broker分布情况，请参考kafka集群partition分布原理分析</p>
<h2 id="2-2-partiton中文件存储方式"><a href="#2-2-partiton中文件存储方式" class="headerlink" title="2.2 partiton中文件存储方式"></a>2.2 partiton中文件存储方式</h2><p>下面示意图形象说明了partition中文件存储方式:</p>
<p><img src="/images/2018/kafka_intro/kafka_partition.png" alt="Sample Image Added via Markdown"></p>
<ul>
<li>每个partion(目录)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除。</li>
<li>每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定。</li>
</ul>
<p>这样做的好处就是能快速删除无用文件，有效提高磁盘利用率。</p>
<h2 id="2-3-partiton中segment文件存储结构"><a href="#2-3-partiton中segment文件存储结构" class="headerlink" title="2.3 partiton中segment文件存储结构"></a>2.3 partiton中segment文件存储结构</h2><p>读者从2.2节了解到Kafka文件系统partition存储方式，本节深入分析partion中segment file组成和物理结构。</p>
<ul>
<li>segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件.</li>
<li>segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充。</li>
</ul>
<p>下面文件列表是笔者在Kafka broker上做的一个实验，创建一个topicXXX包含1 partition，设置每个segment大小为500MB,并启动producer向Kafka broker写入大量数据,如下图2所示segment文件列表形象说明了上述2个规则：</p>
<p><img src="/images/2018/kafka_intro/kafka_index.png" alt="Sample Image Added via Markdown"></p>
<p>以上述图2中一对segment file文件为例，说明segment中index&lt;—-&gt;data file对应关系物理结构如下：</p>
<p>上述图3中索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中message的物理偏移地址。 其中以索引文件中元数据3,497为例，依次在数据文件中表示第3个message(在全局partiton表示第368772个message)、以及该消息的物理偏移地址为497。</p>
<p>从上述图3了解到segment data file由许多message组成，下面详细说明message物理结构如下：<br><img src="/images/2018/kafka_intro/kafka_message.png" alt="Sample Image Added via Markdown"></p>
<p>参数说明：<br>关键字    解释说明<br>8 byte offset    在parition(分区)内的每条消息都有一个有序的id号，这个id号被称为偏移(offset),它可以唯一确定每条消息在parition(分区)内的位置。即offset表示partiion的第多少message<br>4 byte message size    message大小<br>4 byte CRC32    用crc32校验message<br>1 byte “magic”    表示本次发布Kafka服务程序协议版本号<br>1 byte “attributes”    表示为独立版本、或标识压缩类型、或编码类型。<br>4 byte key length    表示key的长度,当key为-1时，K byte key字段不填<br>K byte key    可选<br>value bytes payload    表示实际消息数据。</p>
<h2 id="2-4-在partition中如何通过offset查找message"><a href="#2-4-在partition中如何通过offset查找message" class="headerlink" title="2.4 在partition中如何通过offset查找message"></a>2.4 在partition中如何通过offset查找message</h2><p>例如读取offset=368776的message，需要通过下面2个步骤查找。</p>
<p>第一步查找segment file 上述图2为例，其中00000000000000000000.index表示最开始的文件，起始偏移量(offset)为0.第二个文件00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1.同样，第三个文件00000000000000737337.index的起始偏移量为737338=737337 + 1，其他后续文件依次类推，以起始偏移量命名并排序这些文件，只要根据offset <strong>二分查找</strong>文件列表，就可以快速定位到具体文件。 当offset=368776时定位到00000000000000368769.index|log</p>
<p>第二步通过segment file查找message 通过第一步定位到segment file，当offset=368776时，依次定位到00000000000000368769.index的元数据物理位置和00000000000000368769.log的物理偏移地址，然后再通过00000000000000368769.log顺序查找直到offset=368776为止。</p>
<p>从上述图3可知这样做的优点，segment index file采取稀疏索引存储方式，它减少索引文件大小，通过mmap可以直接内存操作，稀疏索引为数据文件的每个对应message设置一个元数据指针,它比稠密索引节省了更多的存储空间，但查找起来需要消耗更多的时间。</p>
<p>3 Kafka文件存储机制–实际运行效果<br>实验环境：</p>
<p>Kafka集群：由2台虚拟机组成<br>cpu：4核<br>物理内存：8GB<br>网卡：千兆网卡<br>jvm heap: 4GB<br>详细Kafka服务端配置及其优化请参考：kafka server.properties配置详解<br><img src="/images/2018/kafka_intro/kafka_read_disk.png" alt="Sample Image Added via Markdown"></p>
<p>从上述图5可以看出，Kafka运行时很少有大量读磁盘的操作，主要是定期批量写磁盘操作，因此操作磁盘很高效。这跟Kafka文件存储中读写message的设计是息息相关的。Kafka中读写message有如下特点:</p>
<h3 id="写message"><a href="#写message" class="headerlink" title="写message"></a>写message</h3><ul>
<li>消息从java堆转入page cache(即物理内存)。</li>
<li>由异步线程刷盘,消息从page cache刷入磁盘。</li>
</ul>
<h3 id="读message"><a href="#读message" class="headerlink" title="读message"></a>读message</h3><ul>
<li>消息直接从page cache转入socket发送出去。</li>
<li>当从page cache没有找到相应数据时，此时会产生磁盘IO,从磁 盘Load消息到page cache,然后直接从socket发出去</li>
</ul>
<h3 id="Kafka高效文件存储设计特点"><a href="#Kafka高效文件存储设计特点" class="headerlink" title="Kafka高效文件存储设计特点"></a>Kafka高效文件存储设计特点</h3><ul>
<li><p>Kafka把topic中一个partition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</p>
</li>
<li><p>通过索引信息可以快速定位message和确定response的最大大小。</p>
</li>
<li>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。</li>
<li>通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。</li>
</ul>
<p>1.Linux Page Cache机制 </p>
<p>2.Kafka官方文档</p>
<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>面试的时候经常问到Kafka怎么防止重复消费</p>
<ul>
<li><p>比如，你拿到这个消息做数据库的insert操作，那就容易了，给这个消息做一个唯一的主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。</p>
</li>
<li><p>再比如，你拿到这个消息做Redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。</p>
</li>
<li><p>如果上面两种情况还不行，上大招。准备一个第三方介质，来做消费记录。以Redis为例，给消息分配一个全局id，只要消费过该消息，将<id,message>以K-V形式写入Redis. 那消费者开始消费前，先去Redis中查询有没有消费记录即可。</id,message></p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mikolaje.github.io/2018/python_dict.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dennis">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to Dennis Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/python_dict.html" itemprop="url">Python Dict Internal</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-02-14T11:07:10+08:00">
                2018-02-14
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/python_dict.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/python_dict.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>前言：最近在知乎上看到很多Python职位的面试都会问Python的数据结构。很多大公司，比如知乎，在面试python的工程师的时候都会很注重基础；<br>比如会问：python内置的list dict set等使用和原理。collections 模块里的deque，Counter，OrderDict等。 常用的排序算法和时间复杂度。</p>
<p>今天我就简单说说我学到的关于Python Dict 的见闻。</p>
<p>于是，首先我查看到《流畅的python》一书的第3章。</p>
<ol>
<li>首先我们看看Python是如何用散列表来实现dict类型。</li>
</ol>
<p>什么是散列表：<br>散列表其实是一个稀疏数组（总是有空白元素的数组称为稀疏数组）。<br>在一般的数据结构教材中，散列表里的单元通常叫作表元（bucket）。在 dict 的散列表当中，每个键值对都占用一个表元，每个表元都有两<br>个部分，一个是对键的引用，另一个是对值的引用。因为所有表元的大小一致，所以可以通过偏移量来读取某个表元。</p>
<p>散列算法：<br>1.为了获取 my_dict[search_key] 背后的值，Python 首先会调用hash(search_key) 来计算 search_key 的散列值，把这个值最低的几位数字当作偏移量(貌似是hash(key) 和 数组的长度-1 作 与运算，hash(key)&amp; (size-1)，在散列表里查找表元（具体取几位，得看当前散列表的大小）。</p>
<p>2.若找到的表元是空的，则抛出 KeyError 异常。若不是空的，则表元里会有一对 found_key:found_value。</p>
<p>3.这时候 Python 会检验 search_key == found_key 是否为真，如果它们相等的话，就会返回 found_value。</p>
<p>4.如果 search_key 和 found_key 不匹配的话，这种情况称为散列冲突。</p>
<p>5.Python 解决散列冲突的方法用的是开放地址法。<br>如下图所示：<br><img src="/images/2018/python_dict/python_dict1.png" alt="Sample Image Added via Markdown"></p>
<h3 id="Python-dict的特性："><a href="#Python-dict的特性：" class="headerlink" title="Python dict的特性："></a>Python dict的特性：</h3><p>1.字典在内存上的开销巨大。<br>由于字典使用了散列表，而散列表又必须是稀疏的，这导致它在空间上的效率低下。<br>2.键查询很快。<br>dict 的实现是典型的空间换时间：字典类型有着巨大的内存开销，但它们提供了无视数据量大小的快速访问——只要字典能被装在内存里。<br>3.往字典里添加新键可能会改变已有键的顺序。<br>无论何时往字典里添加新的键，Python 解释器都可能做出为字典扩容的决定。扩容导致的结果就是要新建一个更大的散列表，并把字典里已有的元素添加到新表里。</p>
<p>关于Python的开放地制法解决hash冲突的实现可以参考下<br><a href="https://harveyqing.gitbooks.io/python-read-and-write/content/python_advance/python_dict_implementation.html" target="_blank" rel="external">https://harveyqing.gitbooks.io/python-read-and-write/content/python_advance/python_dict_implementation.html</a></p>
<p><img src="/images/2018/python_dict/python_dict2.png" alt="Sample Image Added via Markdown"></p>
<p><em>若要了解详细的内部机制，推荐阅读</em><br><a href="http://python.jobbole.com/85040/" target="_blank" rel="external">http://python.jobbole.com/85040/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="Dennis" />
            
              <p class="site-author-name" itemprop="name">Dennis</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">36</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/mikolaje" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/mikolaj" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-zhihu"></i>知乎</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://stackoverflow.com/users/6169688/dennisli" target="_blank" title="StackOverflow">
                      
                        <i class="fa fa-fw fa-stack-overflow"></i>StackOverflow</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Dennis</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://mikolaje.disqus.com/count.js" async></script>
    

    

  




	





  














  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  
  <script type="text/javascript" src="/js/src/js.cookie.js?v=5.1.4"></script>
  <script type="text/javascript" src="/js/src/scroll-cookie.js?v=5.1.4"></script>


  

</body>
</html>
